---
title: "Diagnostic criteria similarity based on ChatGPT embeddings"
output:
  html_notebook:
    toc: true
    toc_float: true
---
```{r, message = F}
library(tidyverse)
library(here)
source(here("utils/figures.R"))
```

# Introduction

- Transformer embeddings can be used to represent the contextual similarity of different character strings
- These embeddings often capture important relationships between strings based on the information they represent
- As such, these embeddings represent a way to measure the similarity of different symptoms or diagnoses based on how they were used in the large set of ChatGPT training data
- In order to evaluate how similar different MCAS criteria are based on the symptoms they include, these symptoms can be converted into ChatGPT embeddings and then the similarity of these embeddings can be quantified.

## Embedding models

- OpenAI

  | Model                  | Dimensions | Max Tokens |   |   |   |
  |------------------------|:----------:|:----------:|:-:|:-:|:-:|
  | text-embedding-ada-002 |    1536    |    8191    |   |   |   |
  | text-embedding-3-small |    1536    |    8191    |   |   |   |
  | text-embedding-3-large |    3072    |    8191    |   |   |   |

- Voyage AI - Anthropic does not offer an embedding API, but recommends Voyage
  
  | Model                   | Context Length (tokens) | Embedding Dimension |                                                                                                                                                               Description                                                                                                                                                              |   |
  |-------------------------|:-----------------------:|:-------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|---|
  | voyage-large-2-instruct |          16000          |         1024        | Top of MTEB leaderboard. Instruction-tuned general-purpose embedding model optimized for clustering, classification, and retrieval. For retrieval, please use input_type parameter to specify whether the text is a query or document. For classification and clustering, please use the instructions here. See blog post for details. |   |
  | voyage-law-2            |          16000          |         1024        | Optimized for legal and long-context retrieval and RAG. Also improved performance across all domains. See blog post for details.                                                                                                                                                                                                       |   |
  | voyage-code-2           |          16000          |         1536        | Optimized for code retrieval (17% better than alternatives). See blog post for details.                                                                                                                                                                                                                                                |   |
  | voyage-large-2          |          16000          |         1536        | General-purpose embedding model that is optimized for retrieval quality (e.g., better than OpenAI V3 Large).                                                                                                                                                                                                                           |   |
  | voyage-2                |           4000          |         1024        | General-purpose embedding model optimized for a balance between cost, latency, and retrieval quality.                                                                                                                                                                                                                                  |   |
  
- Gemini


# Import data
```{r, message=F}
read_embeddings <- function(path){
  read_csv(path) %>% column_to_rownames("symptom")
}

df_embeddings_chatgpt <- read_embeddings(here("data/chatgpt_embeddings/text-embedding-3-small/symptom_chatgpt_embeddings_text-embedding-3-small.csv")) # Small ChatGPT embedding model
df_embeddings_chatgpt_large <- read_embeddings(here("data/chatgpt_embeddings/text-embedding-3-large/symptom_chatgpt_embeddings_text-embedding-3-large.csv")) # Small ChatGPT embedding model
df_embeddings_voyage <- read_embeddings(here("data/voyage_embeddings/voyage-large-2/symptom_embeddings_voyage-large-2.csv")) # voyage embedding model
df_embeddings_gemini <- read_embeddings(here("data/gemini_embeddings/text-embedding-004/symptom_embeddings_text-embedding-004.csv")) # Gemini embedding model
df_embeddings_mistral <- read_embeddings(here("data/mistral_embeddings/mistral-embed/symptom_embeddings_mistral-embed.csv")) # Gemini embedding model

df_embeddings_chatgpt[1:5,1:5]
df_embeddings_chatgpt_large[1:5,1:5]
df_embeddings_voyage[1:5,1:5]
df_embeddings_gemini[1:5,1:5]
df_embeddings_mistral[1:5,1:5]
```


```{r}
df_criteria <- tibble(criteria = list.files(here("data/disease_criteria"))) %>% 
  mutate(file = here(sprintf("data/disease_criteria/%s", criteria))) %>% 
  mutate(criteria = gsub("_criteria_symptoms\\.csv", "", criteria)) %>% 
  mutate(data = map(file, function(df){
    suppressMessages(read_csv(df)) %>% 
      mutate(feature = str_split(feature, ", "))
  })) 

df_criteria <- df_criteria %>% 
  format_criteria() %>% 
  select(-file) %>% 
  unnest(data) %>% 
  select(-system) %>% 
  unnest(feature)

df_criteria
```
```{r}
# Function to calculate centroids in multi-dimensional space
calculate_centroids <- function(df){
  df %>% 
    rownames_to_column("feature") %>% 
    right_join(df_criteria) %>% 
    nest(.by = criteria) %>% 
    mutate(data = map(data, function(df){
      df %>% 
        drop_na() %>% 
        distinct() %>% 
        column_to_rownames("feature") %>% 
        apply(MARGIN = 2, FUN = mean)
    })) %>% 
    unnest_wider(data) %>% 
    column_to_rownames("criteria")
}

# Function to switch between distances in a single line
custom_dist <- function(df, method = "euclidean"){
  if (method == "euclidean"){
    return(as.matrix(dist(df)))
  }
  if (method == "cosine"){
    return(lsa::cosine(t(as.matrix(df))))
  }
}
```


```{r, fig.width=4.5, fig.height=4, message = F}
# Plot heatmap of distance between centroids using full embeddings
as.data.frame(df_embeddings_chatgpt) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "euclidean") %>% 
  pheatmap::pheatmap(color = viridis::viridis(100, direction = -1), main = "Euclidean")

as.data.frame(df_embeddings_chatgpt) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "cosine") %>% 
  # pheatmap::pheatmap(color = colorRampPalette(RColorBrewer::brewer.pal(11, "BrBG"))(101), main = "Cosine", breaks = seq(-1,1,length.out = 101))
  pheatmap::pheatmap(color = viridis::viridis(100), main = "Cosine")
```
```{r, fig.width=4.5, fig.height=4, message = F}
# Plot heatmap of distance between centroids using full embeddings
as.data.frame(df_embeddings_voyage) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "euclidean") %>% 
  pheatmap::pheatmap(color = viridis::viridis(100, direction = -1), main = "Euclidean")

as.data.frame(df_embeddings_voyage) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "cosine") %>% 
  # pheatmap::pheatmap(color = colorRampPalette(RColorBrewer::brewer.pal(11, "BrBG"))(101), main = "Cosine", breaks = seq(-1,1,length.out = 101))
  pheatmap::pheatmap(color = viridis::viridis(100), main = "Cosine")
```


- With full embedding space, cosine similarity doesn't have enough resolution. Likely because disease terms occupy a relatively similar reagion of the ChatGPT embedding space


# PCA analysis

- Instead of working with full embedding space, reduce variability via PCA

```{r}
scaling = T
pca_chatgpt <- prcomp(df_embeddings_chatgpt, scale. = scaling) %>% summary()
pca_chatgpt_large <- prcomp(df_embeddings_chatgpt_large, scale. = scaling) %>% summary()
pca_voyage <- prcomp(df_embeddings_voyage, scale. = scaling) %>% summary()
pca_gemini <- prcomp(df_embeddings_gemini, scale. = scaling) %>% summary()
pca_mistral <- prcomp(df_embeddings_mistral, scale. = scaling) %>% summary()
```

```{r, fig.width=5, fig.height=4}
# Cumulative proportion of variance explained by component
cumulative_variance_plot <- function(pca_data){
  pca_data$importance %>% t() %>% as.data.frame() %>% 
    rownames_to_column("component") %>% 
    mutate(component = as.numeric(str_extract(component, "[0-9]+"))) %>% 
    # ggplot(aes(x=component, y = `Proportion of Variance`)) +
    ggplot(aes(x=component, y = `Cumulative Proportion`)) +
    geom_path()+
    theme_bw()
}

cumulative_variance_plot(pca_chatgpt)+ggtitle("ChatGPT")
cumulative_variance_plot(pca_chatgpt_large)+ggtitle("ChatGPT Large")
cumulative_variance_plot(pca_voyage)+ggtitle("voyage")
cumulative_variance_plot(pca_gemini)+ggtitle("Gemini")
cumulative_variance_plot(pca_mistral)+ggtitle("Mistral")
```
- No clear set of PCA components to use for calculations. Supports using all components for distance calculations

### PCA Plot
```{r}
# Plot PCA reductions with criteria centroids
pca_centroid_plot <- function(pca_data, criteria_key, components = c(1,2)){
  axes <- colnames(pca_data$x)[components]
  
  pca_data$x[,components] %>% 
    as.data.frame() %>% 
    rownames_to_column("feature") %>% 
    left_join(criteria_key) %>% 
    drop_na() %>% 
    ggplot(aes(x=!!sym(axes[1]), y=!!sym(axes[2]), color = criteria))+
    geom_point(size = 0.5) +
    geom_point(data = . %>% group_by(criteria) %>% summarise_at(vars(contains("PC")), mean), size = 3, shape = 21, color = "black", aes(fill = criteria))+
    # stat_ellipse(size = 2, type = "t", level = 0.95)+
    # facet_wrap(~criteria) +
    theme_bw()+
    scale_color_brewer(palette = "Dark2")+
    scale_fill_brewer(palette = "Dark2") +
    labs(color = "", fill = "")
}
```


```{r, fig.width=6, fig.height=4}
pca_centroid_plot(pca_chatgpt, df_criteria)+ggtitle("ChatGPT")
pca_centroid_plot(pca_chatgpt_large, df_criteria)+ggtitle("ChatGPT Large")
pca_centroid_plot(pca_voyage, df_criteria)+ggtitle("voyage")
pca_centroid_plot(pca_gemini, df_criteria)+ggtitle("Gemini")
pca_centroid_plot(pca_mistral, df_criteria)+ggtitle("Mistral")
```
- Using the two SLE criteria as a reference for similarity, plot demonstrates increased distance between the two MCAS criteria
```{r}
format_embeddings <- function(df){
  
  # Input checks, must be data frame with model column
  arg_col <- makeAssertCollection()
  assertClass(df, "data.frame" , add = arg_col)
  assertNames(names(df), must.include = "model", add = arg_col)
  if (arg_col$isEmpty()==F) {map(arg_col$getMessages(),print);reportAssertions(arg_col)}
  
  models <- c("chatgpt", "gemini", "voyage", "mistral")
  
  df <- mutate(df, model = str_extract(model, paste(models, collapse = "|")))
  
  model_order <- c(
    "chatgpt", 
    "voyage", 
    "gemini", 
    "mistral"
  )
  
  model_names <- c(
    "chatgpt" = "OpenAI Text 3 Small",
    "voyage" = "Voyage 2 Large",
    "gemini" = "Gemini Text 4",
    "mistral" = "Mistral Embed")
  
  df %>% 
    mutate(model = factor(model, levels = model_order)) %>%
    mutate(model = fct_recode(model, !!!setNames(names(model_names), model_names)))
}
```

```{r, fig.width=5, fig.height=5}
multi_pca_centroid_plot <- function(criteria_key, components = c(1,2), ...){
  
  pca_list <- listN(...)
  
  axes <- colnames(pca_list[[1]]$x)[components]
  
  pca_list %>% 
    lapply(., function(x) {
      x <- x$x[,components]
      x <- as.data.frame(x)
      rownames_to_column(x, "feature")
    }) %>% 
    mapply(function(x,y){mutate(x, model=y)}, ., names(.), SIMPLIFY = F) %>% 
    bind_rows() %>% 
    left_join(criteria_key) %>% 
    drop_na() %>%
    format_embeddings() %>% 
    ggplot(aes(x=!!sym(axes[1]), y=!!sym(axes[2]), color = criteria))+
    geom_point(size = 0.5) +
    geom_point(data = . %>% group_by(criteria) %>% summarise_at(vars(contains("PC")), mean), size = 2, shape = 21, color = "black", aes(fill = criteria))+
    # stat_ellipse(size = 2, type = "t", level = 0.95)+
    facet_wrap(~model, scales = "free") +
    theme_bw()+
    scale_color_brewer(palette = "Dark2")+
    scale_fill_brewer(palette = "Dark2") +
    labs(color = "", fill = "")
}


multi_pca_centroid_plot(criteria_key = df_criteria, components = c(1,3), pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) +theme(legend.position = "bottom", legend.direction = "horizontal")
```




### Mean distance plot

```{r}
make_distance_key <- function(data, metric = "euclidean"){
  if (class(data) == "summary.prcomp"){data <- data$x}
  if (metric == "euclidean"){data <- dist(data)}
  if (metric == "cosine"){
    # data <- as.matrix(data)
    data <- t(data)
    data <- lsa::cosine(data)
    data <- as.dist(data)
  }
  
  data %>% 
    broom::tidy() %>% 
    mutate_at(vars(contains("item")), as.character) %>% 
    mutate(symptom_pair = map2(item1, item2, ~sort(c(.x,.y)))) %>% 
    unnest_wider(symptom_pair, names_sep = "") %>% 
    unite(symptom_pair, symptom_pair1, symptom_pair2, sep = " : ") %>% 
    select(symptom_pair, distance)
}


calculate_distance <- function(distance_key, criteria_key){
  df_distance_comp <- tribble(
    ~criteria1, ~criteria2,
    "SLE - EULAR-ACR", "SLE - SLICC",
    "MCAS - Consortium", "MCAS - Alternative"
  ) %>% 
    left_join(criteria_key, by = c("criteria1" = "criteria")) %>% 
    left_join(criteria_key, by = c("criteria2" = "criteria")) %>% 
    mutate(symptom_pair = map2(feature.x, feature.y, ~sort(c(.x,.y)))) %>% 
    unnest_wider(symptom_pair, names_sep = "") %>% 
    unite(symptom_pair, symptom_pair1, symptom_pair2, sep = " : ") %>% 
    unite(criteria_pair, criteria1, criteria2, sep = " : ") %>% 
    select(criteria_pair, symptom_pair) %>% 
    left_join(distance_key, by = "symptom_pair") %>% 
    drop_na() %>% 
    mutate(criteria_pair = gsub(" : ", "\nvs. ", criteria_pair)) 
  
  return(df_distance_comp)
}

plot_distance <- function(distance_comp){
  
  distance_comp %>%
    ggplot(aes(x = criteria_pair, y = distance))+
    stat_summary(fun = mean, geom = "point", size = 0.5) +
    stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.5)+
    ggpubr::stat_compare_means(method = "wilcox.test", label = "p", vjust = 1)+
    theme_bw() +
    theme(axis.text.x = element_text(angle =90, hjust =1)) +
    labs(x="", y="Euclidean distance") 
}

plot_distance_wrapper <- function(data, criteria_key, metric = "euclidean"){
    distance_key <- make_distance_key(data, metric = metric)
    distance_comp <- calculate_distance(distance_key, criteria_key)
    plot_distance(distance_comp)
}
```

```{r, fig.width=2, fig.height=4}
plot_distance_wrapper(pca_chatgpt, df_criteria) + ggtitle("ChatGPT", "PCA")
plot_distance_wrapper(pca_chatgpt_large, df_criteria) + ggtitle("ChatGPT Large", "PCA")
plot_distance_wrapper(pca_voyage, df_criteria) + ggtitle("voyage", "PCA")
plot_distance_wrapper(pca_gemini, df_criteria) + ggtitle("Gemini", "PCA")
plot_distance_wrapper(pca_mistral, df_criteria) + ggtitle("Mistral", "PCA")

```
```{r, fig.width=2, fig.height=4}
plot_distance_wrapper(df_embeddings_chatgpt, df_criteria) + ggtitle("ChatGPT", "Embeddings")
plot_distance_wrapper(df_embeddings_chatgpt_large, df_criteria) + ggtitle("ChatGPT Large", "Embeddings")
plot_distance_wrapper(df_embeddings_voyage, df_criteria) + ggtitle("voyage", "Embeddings")
plot_distance_wrapper(df_embeddings_gemini, df_criteria) + ggtitle("Gemini", "Embeddings")
plot_distance_wrapper(df_embeddings_mistral, df_criteria) + ggtitle("Mistral", "Embeddings")
```





```{r, fig.width=2, fig.height=4}
plot_distance_wrapper(pca_chatgpt, df_criteria, metric = "cosine") + ggtitle("ChatGPT", "PCA") + geom_violin()
plot_distance_wrapper(pca_chatgpt_large, df_criteria, metric = "cosine") + ggtitle("ChatGPT Large", "PCA") + geom_violin()
plot_distance_wrapper(pca_voyage, df_criteria, metric = "cosine") + ggtitle("voyage", "PCA") + geom_violin()
plot_distance_wrapper(pca_gemini, df_criteria, metric = "cosine") + ggtitle("Gemini", "PCA") + geom_violin()

```
```{r, fig.width=2, fig.height=4}
plot_distance_wrapper(df_embeddings_chatgpt, df_criteria, metric = "cosine") + ggtitle("ChatGPT", "Embeddings") + geom_violin()
plot_distance_wrapper(df_embeddings_chatgpt_large, df_criteria, metric = "cosine") + ggtitle("ChatGPT Large", "Embeddings") + geom_violin()
plot_distance_wrapper(df_embeddings_voyage, df_criteria, metric = "cosine") + ggtitle("voyage", "Embeddings") + geom_violin()
plot_distance_wrapper(df_embeddings_gemini, df_criteria, metric = "cosine") + ggtitle("Gemini", "Embeddings") + geom_violin()
```

````{r, fig.width=5, fig.height=4}
listN(pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) %>% 
  lapply(., function(x){
    make_distance_key(data = x, metric = "cosine") %>% 
    calculate_distance(distance_key = ., criteria_key = df_criteria)
  }) %>% 
  mapply(function(x,y) {mutate(x, model=y)}, ., names(.), SIMPLIFY = F) %>% 
  bind_rows() %>% 
  plot_distance()+
  facet_wrap(~model)+
  geom_violin()+
  stat_summary(fun = mean, geom = "point") +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.3)
  
```


# Centroids

```{r}
dist_wrapper <- function(data){
  as.data.frame(data$x) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "cosine") %>% 
  as.data.frame() %>% 
  rownames_to_column("V1") %>% 
  pivot_longer(-V1, names_to = "V2", values_to = "metric")
}

dist_wrapper(pca_chatgpt)
```
```{r, fig.width=3.5, fig.height=4}
listN(pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) %>% 
  lapply(., dist_wrapper) %>%  
  mapply(function(x,y) {mutate(x, model=y)}, ., names(.), SIMPLIFY = F) %>% 
  bind_rows() %>% 
  unite(comp, V1, V2) %>% 
  filter(comp %in% c("MCAS - Consortium_MCAS - Alternative", "SLE - EULAR-ACR_SLE - SLICC")) %>% 
  mutate(comp = gsub("_", "\nvs. ", comp)) %>%  
  format_embeddings() %>% 
  ggplot(aes(x = comp, y = metric, color = model))+
  geom_point(position = position_dodge(width = 0.75))+
  # stat_summary(fun = mean, geom = "point", color = "black")+
  theme_bw() +
  ggpubr::stat_compare_means(aes(group = comp), method = "wilcox.test", label = "p", vjust = 1, show.legend = F)+
    # theme_bw() +
  theme(axis.text.x = element_text(angle =90, hjust =1)) +
  labs(x="", y="Cosine similarity") +
  ylim(-0.1,1) +
  scale_color_brewer(palette = "Set1") +
  labs(color = "")

```

```{r}
dist_wrapper <- function(data){
  as.data.frame(data$x) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "cosine") %>% 
  as.data.frame() %>% 
  rownames_to_column("V1") %>% 
  pivot_longer(-V1, names_to = "V2", values_to = "metric")
}

dist_wrapper(pca_chatgpt)


cosine_data <- listN(pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) %>% 
  lapply(., function(x) {as.data.frame(x$x) %>% calculate_centroids() %>% rownames_to_column("criteria")}) %>%  
  mapply(function(x,y) {mutate(x, model=y)}, ., names(.), SIMPLIFY = F) %>% 
  bind_rows() %>% 
  unite(sample, criteria, model) %>% 
  column_to_rownames("sample") %>% 
  custom_dist(method = "cosine")
  

ComplexHeatmap::Heatmap(cosine_data)
```

```{r}
unique(df_criteria$criteria  )
```



```{r, fig.width=5.5, fig.height=3.5}
custom_heatmap2 <- function(data, 
                           title, 
                           metric, 
                           color_scale = hcl.colors(3, "Earth"), 
                           midpoint = NULL, 
                           symmetric = T, 
                           font_size=10,
                           dendrogram_weight = unit(10, "mm"),
                           legend_params = list(NULL)){
  scale_max <- ifelse(symmetric,max(abs(data)),max(data))
  scale_min <- ifelse(symmetric,-max(abs(data)),min(data))
  scale_mid <- scale_min + (scale_max - scale_min)/2
  
  midpoint <- ifelse(is.null(midpoint), scale_mid, midpoint)
  
  color_function <-circlize::colorRamp2(c(scale_min,midpoint,scale_max), color_scale)
  

  annotation_data <- data.frame(
  rownames = rownames(cosine_data),
  model = str_extract(rownames(cosine_data), "gpt|voyage|gemini|mistral"),
  criteria = str_extract(rownames(cosine_data), "Migraine - ICHD3|Kawasaki - AHA|SLE - EULAR-ACR|SLE - SLICC|MCAS - Consortium|MCAS - Alternative")
) %>% 
  column_to_rownames("rownames")

  model_colors <- colorspace::lighten(brewer.pal(4, "Dark2"), amount = -0.1)
  names(model_colors) <- unique(annotation_data$model)
  
  criteria_colors <- colorspace::lighten(brewer.pal(6, "Set1"), amount = 0.3)
  names(criteria_colors) <- unique(annotation_data$criteria)
  
  col_annotation <- HeatmapAnnotation(
    Model = annotation_data$model,
    Criteria = annotation_data$criteria,
    col = list(Model = model_colors, Criteria = criteria_colors)
  )
  
  ComplexHeatmap::Heatmap(
    data,
    col = color_function,
    top_annotation = col_annotation,
    show_row_names = FALSE,
    show_column_names = FALSE,
    cluster_columns = TRUE,
    cluster_rows = TRUE,
    
    column_title = title,
    name = metric,
    column_dend_height  = dendrogram_weight,
    row_dend_width = dendrogram_weight,
  )
  
}
  
custom_heatmap2(cosine_data, 
                color_scale = RColorBrewer::brewer.pal(5, "BrBG")[c(1,3,5)], 
                title = " ", 
                metric = "Cosine\nsimilarity", 
                symmetric = T,
                font_size = 8)  
  

```

```{r}
listN(pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) %>% 
  lapply(., dist_wrapper) %>%  
  mapply(function(x,y) {mutate(x, model=y)}, ., names(.), SIMPLIFY = F) %>% 
  bind_rows() %>% 
  unite(comp, V1, V2) %>% 
  summarise(metric = mean(metric), .by = "comp") %>% 
  separate(comp, into = c("V1", "V2"), sep = "_") %>% 
  pivot_wider(names_from = "V2", values_from = "metric") %>% 
  column_to_rownames("V1") %>% 
  ComplexHeatmap::Heatmap()

```

### Centroid distance heatmap

```{r, fig.width=4.5, fig.height=4, message = F}
# Plot heatmap of distance between centroids in PCA space
as.data.frame(pca_embedding$x) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "euclidean") %>% 
  pheatmap::pheatmap(color = viridis::viridis(100, direction = -1), main = "Euclidean")

as.data.frame(pca_embedding$x) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "cosine") %>% 
  pheatmap::pheatmap(color = colorRampPalette(RColorBrewer::brewer.pal(11, "BrBG"))(101), main = "Cosine", breaks = seq(-1,1,length.out = 101))
```

```{r, fig.width=4.5, fig.height=4, message = F}
# Plot heatmap of distance between centroids using full embeddings
as.data.frame(pca_chatgpt$x) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "euclidean") %>% 
  pheatmap::pheatmap(color = viridis::viridis(100, direction = -1), main = "Euclidean")

as.data.frame(df_embeddings_chatgpt) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "cosine") %>% 
  # pheatmap::pheatmap(color = colorRampPalette(RColorBrewer::brewer.pal(11, "BrBG"))(101), main = "Cosine", breaks = seq(-1,1,length.out = 101))
  pheatmap::pheatmap(color = viridis::viridis(100), main = "Cosine")
```



### Dendrogram significance
```{r, fig.width=6, fig.height=6, message = F}
cosine <- function(x) {
  x <- as.matrix(x)
  y <- t(x) %*% x
  res <- 1 - y / (sqrt(diag(y)) %*% t(sqrt(diag(y))))
  res <- as.dist(res)
  attr(res, "method") <- "cosine"
  return(res)
}


pvclust_pca <- as.data.frame(pca_embedding$x) %>% 
  calculate_centroids() %>% 
  t() %>% 
  pvclust::pvclust(nboot = 500, method.dist = cosine, quiet = T)
plot(pvclust_pca)
pvclust::pvrect(pvclust_pca, alpha = 0.95)
```


# UMAP 
```{r, message = F}
# names(umap::umap.defaults)
set.seed(1234)
umap_gpt <- umap::umap(df_embeddings)
# umap_cluster <- umap::umap(df_embeddings, n_components = 2)
```

### UMAP plot

```{r, message = F}
# Plot UMAP of embeddings
umap_gpt$layout %>% 
  as.data.frame() %>% 
  rownames_to_column("feature") %>% 
  left_join(df_criteria) %>% 
  drop_na() %>% 
  ggplot(aes(x=V1, y=V2, color = criteria))+
  geom_point(size = 1) +
  theme_bw() +
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")
```

# Final figure
```{r, fig.width=6, fig.height=6, message=F}
plt_1 <- pca_embedding$x[,c(x,y)] %>% 
  as.data.frame() %>% 
  rownames_to_column("feature") %>% 
  left_join(df_criteria) %>% 
  drop_na() %>% 
  ggplot(aes(x=!!sym(x), y=!!sym(y), color = criteria))+
  geom_point(size = 0.5) +
  geom_point(data = . %>% group_by(criteria) %>% summarise_at(vars(contains("PC")), mean), size = 3, shape = 21, color = "black", aes(fill = criteria))+
  # stat_ellipse(size = 2, type = "t", level = 0.95)+
  # facet_wrap(~criteria) +
  theme_bw()+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(fill = "", color = "")

plt_2 <- df_compare_euc %>% 
  ggplot(aes(x = criteria_pair, y = distance))+
  stat_summary(fun = mean, geom = "point", size = 1) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.5)+
  ggpubr::stat_pvalue_manual(
    ggpubr::compare_means(distance ~ criteria_pair, df_compare_euc, method = "wilcox.test"),
    label = "p = {p.adj}",
    y.position = 55.6,
    tip.length = 0.001
  )+
  theme_bw() +
  theme(axis.text.x = element_text(angle =90, hjust =1)) +
  labs(x="", y="Euclidean distance") +
  coord_cartesian(ylim=c(NA,55.75))

cp_font <- 9
plt_3 <- as.data.frame(pca_embedding$x) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "euclidean") %>% 
  # pheatmap::pheatmap(color = viridis::viridis(100, direction = -1))
  ComplexHeatmap::Heatmap(
    col = viridis::viridis(100, direction = -1), 
    name= "Euclidean\ndistance",
    rect_gp = grid::gpar(col = "black", lwd = 1),
    row_names_gp = grid::gpar(fontsize = cp_font),  # Adjust font size for row labels
  column_names_gp = grid::gpar(fontsize = cp_font)  # Adjust font size for column labels
  )

# cowplot::plot_grid(
# cowplot::plot_grid(plt_1, plt_2, nrow = 1, rel_widths = c(0.7,0.3), align = "h", axis = "tb"),
# cowplot::plot_grid(NULL, plt_3$gtable, NULL, nrow =1, rel_widths = c(0.2, 0.6,0.15)),
# ncol = 1)

plt_fig <- cowplot::plot_grid(
  cowplot::plot_grid(
    NULL,
    plt_1,
    NULL,
    nrow = 1,
    rel_widths = c(0.1, 0.8, 0.1),
    align = "h",
    axis = "tb",
    labels = c("", "A", "")
  ),
  # cowplot::plot_grid(plt_2, NULL, plt_3$gtable, nrow =1, rel_widths = c(0.3, 0.1, 0.7), align = "h", axis = "tb", labels = c("B","C")),
  cowplot::plot_grid(
    plt_2,
    NULL,
    cowplot::plot_grid(
      grid::grid.grabExpr(ComplexHeatmap::draw(plt_3)),
      NULL,
      ncol = 1,
      rel_heights = c(0.9, 0.1)
    ),
    nrow = 1,
    rel_widths = c(0.3, 0.051, 0.7),
    labels = c("B", "", "C")
  ),
  ncol = 1,
  rel_heights = c(0.4, 0.6)
)

plt_fig
```
```{r}
ggsave(here("figures/2_Criteria_embedding.pdf"), plot=plt_fig, height = 6, width = 6)
```

# Altenative layout
```{r, fig.width=7, fig.height=3.5, message=F}
title_size <- 9
label_size <- 6

apply_text_formatting <- list(theme(
  axis.text = element_text(size = label_size),
  axis.title = element_text(size = title_size),
  legend.text = element_text(size = label_size),
  legend.key.height = unit(0.4, 'cm')
  ))

plt_1 <- pca_embedding$x[,c(x,y)] %>% 
  as.data.frame() %>% 
  rownames_to_column("feature") %>% 
  left_join(df_criteria) %>% 
  drop_na() %>% 
  ggplot(aes(x=!!sym(x), y=!!sym(y), color = criteria))+
  geom_point(size = 0.5) +
  geom_point(data = . %>% group_by(criteria) %>% summarise_at(vars(contains("PC")), mean), size = 3, shape = 21, color = "black", aes(fill = criteria))+
  theme_bw()+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(fill = "", color = "") +
  theme(legend.position = "bottom") +
  guides(color = guide_legend(ncol = 2))

plt_2 <- df_compare_euc %>% 
  ggplot(aes(x = criteria_pair, y = distance))+
  stat_summary(fun = mean, geom = "point", size = 1) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.5)+
  ggpubr::stat_pvalue_manual(
    ggpubr::compare_means(distance ~ criteria_pair, df_compare_euc, method = "wilcox.test"),
    label = "p = {p.adj}",
    y.position = 55.6,
    tip.length = 0.001, label.size = 3
  )+
  theme_bw() +
  theme(axis.text.x = element_text(angle =90, hjust =1)) +
  labs(x="", y="Euclidean distance") +
  coord_cartesian(ylim=c(NA,55.75))

plt_3 <- as.data.frame(pca_embedding$x) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "euclidean") %>% 
  # pheatmap::pheatmap(color = viridis::viridis(100, direction = -1))
  ComplexHeatmap::Heatmap(
    col = viridis::viridis(100, direction = -1), 
    name= "Euclidean distance",
    heatmap_legend_param = list(direction = "horizontal"),
    rect_gp = grid::gpar(col = "black", lwd = 1),
    row_names_gp = grid::gpar(fontsize = label_size),  # Adjust font size for row labels
    column_names_gp = grid::gpar(fontsize = label_size)  # Adjust font size for column labels
  )

plt_fig <- cowplot::plot_grid(
    plt_1 + apply_text_formatting,
    plt_2 + apply_text_formatting,
    grid::grid.grabExpr(ComplexHeatmap::draw(plt_3, heatmap_legend_side = 'bottom')),
    rel_widths = c(0.9, 0.5, 1),
    axis = 'bt',
    align = 'h',
    labels = LETTERS[1:3],
    nrow = 1
)

plt_fig
```

```{r}
ggsave(here("figures/2_Criteria_embedding.pdf"), plot=plt_fig, height = 3.5, width = 7)
```




