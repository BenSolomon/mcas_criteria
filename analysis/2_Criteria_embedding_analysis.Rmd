---
title: "Diagnostic criteria similarity based on ChatGPT embeddings"
output:
  html_notebook:
    toc: true
    toc_float: true
---
```{r, message = F}
library(tidyverse)
library(here)
source(here("utils/figures.R"))
source(here("utils/general.R"))
```

# Introduction

- Transformer embeddings can be used to represent the contextual similarity of different character strings
- These embeddings often capture important relationships between strings based on the information they represent
- As such, these embeddings represent a way to measure the similarity of different symptoms or diagnoses based on how they were used in the large set of ChatGPT training data
- In order to evaluate how similar different MCAS criteria are based on the symptoms they include, these symptoms can be converted into ChatGPT embeddings and then the similarity of these embeddings can be quantified.

## Embedding models

- OpenAI

  | Model                  | Dimensions | Max Tokens |   |   |   |
  |------------------------|:----------:|:----------:|:-:|:-:|:-:|
  | text-embedding-ada-002 |    1536    |    8191    |   |   |   |
  | text-embedding-3-small |    1536    |    8191    |   |   |   |
  | text-embedding-3-large |    3072    |    8191    |   |   |   |

- Voyage AI - Anthropic does not offer an embedding API, but recommends Voyage
  
  | Model                   | Context Length (tokens) | Embedding Dimension |                                                                                                                                                               Description                                                                                                                                                              |   |
  |-------------------------|:-----------------------:|:-------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|---|
  | voyage-large-2-instruct |          16000          |         1024        | Top of MTEB leaderboard. Instruction-tuned general-purpose embedding model optimized for clustering, classification, and retrieval. For retrieval, please use input_type parameter to specify whether the text is a query or document. For classification and clustering, please use the instructions here. See blog post for details. |   |
  | voyage-law-2            |          16000          |         1024        | Optimized for legal and long-context retrieval and RAG. Also improved performance across all domains. See blog post for details.                                                                                                                                                                                                       |   |
  | voyage-code-2           |          16000          |         1536        | Optimized for code retrieval (17% better than alternatives). See blog post for details.                                                                                                                                                                                                                                                |   |
  | voyage-large-2          |          16000          |         1536        | General-purpose embedding model that is optimized for retrieval quality (e.g., better than OpenAI V3 Large).                                                                                                                                                                                                                           |   |
  | voyage-2                |           4000          |         1024        | General-purpose embedding model optimized for a balance between cost, latency, and retrieval quality.                                                                                                                                                                                                                                  |   |
  
- Gemini

- Mistral


# Import data
```{r, message=F}
read_embeddings <- function(path){
  read_csv(path) %>% column_to_rownames("symptom")
}

df_embeddings_chatgpt <- read_embeddings(here("data/chatgpt_embeddings/text-embedding-3-small/symptom_chatgpt_embeddings_text-embedding-3-small.csv")) # Small ChatGPT embedding model
df_embeddings_chatgpt_large <- read_embeddings(here("data/chatgpt_embeddings/text-embedding-3-large/symptom_chatgpt_embeddings_text-embedding-3-large.csv")) # Small ChatGPT embedding model
df_embeddings_voyage <- read_embeddings(here("data/voyage_embeddings/voyage-large-2/symptom_embeddings_voyage-large-2.csv")) # voyage embedding model
df_embeddings_gemini <- read_embeddings(here("data/gemini_embeddings/text-embedding-004/symptom_embeddings_text-embedding-004.csv")) # Gemini embedding model
df_embeddings_mistral <- read_embeddings(here("data/mistral_embeddings/mistral-embed/symptom_embeddings_mistral-embed.csv")) # Gemini embedding model

df_embeddings_chatgpt[1:5,1:5]
df_embeddings_chatgpt_large[1:5,1:5]
df_embeddings_voyage[1:5,1:5]
df_embeddings_gemini[1:5,1:5]
df_embeddings_mistral[1:5,1:5]
```


```{r}
df_criteria <- tibble(criteria = list.files(here("data/disease_criteria"))) %>% 
  mutate(file = here(sprintf("data/disease_criteria/%s", criteria))) %>% 
  mutate(criteria = gsub("_criteria_symptoms\\.csv", "", criteria)) %>% 
  mutate(data = map(file, function(df){
    suppressMessages(read_csv(df)) %>% 
      mutate(feature = str_split(feature, ", "))
  })) 

df_criteria <- df_criteria %>% 
  format_criteria() %>% 
  select(-file) %>% 
  unnest(data) %>% 
  select(-system) %>% 
  unnest(feature)

df_criteria
```

# PCA analysis

- Instead of working with full embedding space, reduce variability via PCA

```{r}
scaling = T
pca_chatgpt <- prcomp(df_embeddings_chatgpt, scale. = scaling) %>% summary()
pca_chatgpt_large <- prcomp(df_embeddings_chatgpt_large, scale. = scaling) %>% summary()
pca_voyage <- prcomp(df_embeddings_voyage, scale. = scaling) %>% summary()
pca_gemini <- prcomp(df_embeddings_gemini, scale. = scaling) %>% summary()
pca_mistral <- prcomp(df_embeddings_mistral, scale. = scaling) %>% summary()
```

```{r, fig.width=5, fig.height=4}
cumulative_variance_plot(pca_chatgpt)+ggtitle("ChatGPT")
cumulative_variance_plot(pca_chatgpt_large)+ggtitle("ChatGPT Large")
cumulative_variance_plot(pca_voyage)+ggtitle("voyage")
cumulative_variance_plot(pca_gemini)+ggtitle("Gemini")
cumulative_variance_plot(pca_mistral)+ggtitle("Mistral")
```
- No clear set of PCA components to use for calculations. Supports using all components for distance calculations

### PCA embeddings with centroids

```{r, fig.width=6, fig.height=4}
pca_centroid_plot(pca_chatgpt, df_criteria)+ggtitle("ChatGPT")
pca_centroid_plot(pca_chatgpt_large, df_criteria)+ggtitle("ChatGPT Large")
pca_centroid_plot(pca_voyage, df_criteria)+ggtitle("Voyage")
pca_centroid_plot(pca_gemini, df_criteria)+ggtitle("Gemini")
pca_centroid_plot(pca_mistral, df_criteria)+ggtitle("Mistral")
```
- Using the two SLE criteria as a reference for similarity, plot demonstrates increased distance between the two MCAS criteria


```{r, fig.width=5, fig.height=5}
multi_pca_centroid_plot(criteria_key = df_criteria, components = c(1,3), pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) +theme(legend.position = "bottom", legend.direction = "horizontal")
```

### Mean distance between symptoms

```{r}
make_distance_key <- function(data, metric = "euclidean"){
  if (class(data) == "summary.prcomp"){data <- data$x}
  if (metric == "euclidean"){data <- dist(data)}
  if (metric == "cosine"){
    # data <- as.matrix(data)
    data <- t(data)
    data <- lsa::cosine(data)
    data <- as.dist(data)
  }
  
  data %>% 
    broom::tidy() %>% 
    mutate_at(vars(contains("item")), as.character) %>% 
    mutate(symptom_pair = map2(item1, item2, ~sort(c(.x,.y)))) %>% 
    unnest_wider(symptom_pair, names_sep = "") %>% 
    unite(symptom_pair, symptom_pair1, symptom_pair2, sep = " : ") %>% 
    select(symptom_pair, distance)
}


calculate_distance <- function(distance_key, criteria_key){
  df_distance_comp <- tribble(
    ~criteria1, ~criteria2,
    "SLE - EULAR-ACR", "SLE - SLICC",
    "MCAS - Consortium", "MCAS - Alternative"
  ) %>% 
    left_join(criteria_key, by = c("criteria1" = "criteria")) %>% 
    left_join(criteria_key, by = c("criteria2" = "criteria")) %>% 
    mutate(symptom_pair = map2(feature.x, feature.y, ~sort(c(.x,.y)))) %>% 
    unnest_wider(symptom_pair, names_sep = "") %>% 
    unite(symptom_pair, symptom_pair1, symptom_pair2, sep = " : ") %>% 
    unite(criteria_pair, criteria1, criteria2, sep = " : ") %>% 
    select(criteria_pair, symptom_pair) %>% 
    left_join(distance_key, by = "symptom_pair") %>% 
    drop_na() %>% 
    mutate(criteria_pair = gsub(" : ", "\nvs. ", criteria_pair)) 
  
  return(df_distance_comp)
}

plot_distance <- function(distance_comp){
  
  distance_comp %>%
    ggplot(aes(x = criteria_pair, y = distance))+
    geom_violin()+
    stat_summary(fun = mean, geom = "point", size = 0.5) +
    stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.75)+
    ggpubr::stat_compare_means(method = "wilcox.test", label = "p", vjust = -1)+
    theme_bw() +
    theme(axis.text.x = element_text(angle =90, hjust =1)) +
    labs(x="", y="") +
    scale_y_continuous(expand = expansion(mult=c(0.05,0.25)))
}

plot_distance_wrapper <- function(data, criteria_key, metric = "euclidean"){
    distance_key <- make_distance_key(data, metric = metric)
    distance_comp <- calculate_distance(distance_key, criteria_key)
    plot_distance(distance_comp) + labs(y=metric)
}
```

```{r, fig.width=2, fig.height=4}
# Euclidean distance between PCA embeddings
plot_distance_wrapper(pca_chatgpt, df_criteria) + ggtitle("ChatGPT", "PCA")
plot_distance_wrapper(pca_chatgpt_large, df_criteria) + ggtitle("ChatGPT Large", "PCA")
plot_distance_wrapper(pca_voyage, df_criteria) + ggtitle("voyage", "PCA")
plot_distance_wrapper(pca_gemini, df_criteria) + ggtitle("Gemini", "PCA")
plot_distance_wrapper(pca_mistral, df_criteria) + ggtitle("Mistral", "PCA")
```
```{r, fig.width=2, fig.height=4}
# Euclidean distance between full embeddings
plot_distance_wrapper(df_embeddings_chatgpt, df_criteria) + ggtitle("ChatGPT", "Embeddings")
plot_distance_wrapper(df_embeddings_chatgpt_large, df_criteria) + ggtitle("ChatGPT Large", "Embeddings")
plot_distance_wrapper(df_embeddings_voyage, df_criteria) + ggtitle("voyage", "Embeddings")
plot_distance_wrapper(df_embeddings_gemini, df_criteria) + ggtitle("Gemini", "Embeddings")
plot_distance_wrapper(df_embeddings_mistral, df_criteria) + ggtitle("Mistral", "Embeddings")
```





```{r, fig.width=2, fig.height=4}
# Cosine similarity between PCA embeddings
plot_distance_wrapper(pca_chatgpt, df_criteria, metric = "cosine") + ggtitle("ChatGPT", "PCA")
plot_distance_wrapper(pca_chatgpt_large, df_criteria, metric = "cosine") + ggtitle("ChatGPT Large", "PCA") 
plot_distance_wrapper(pca_voyage, df_criteria, metric = "cosine") + ggtitle("voyage", "PCA")
plot_distance_wrapper(pca_gemini, df_criteria, metric = "cosine") + ggtitle("Gemini", "PCA")

```
```{r, fig.width=2, fig.height=4}
# Cosine similarity between full embeddings
plot_distance_wrapper(df_embeddings_chatgpt, df_criteria, metric = "cosine") + ggtitle("ChatGPT", "Embeddings")
plot_distance_wrapper(df_embeddings_chatgpt_large, df_criteria, metric = "cosine") + ggtitle("ChatGPT Large", "Embeddings")
plot_distance_wrapper(df_embeddings_voyage, df_criteria, metric = "cosine") + ggtitle("voyage", "Embeddings")
plot_distance_wrapper(df_embeddings_gemini, df_criteria, metric = "cosine") + ggtitle("Gemini", "Embeddings")
```

````{r, fig.width=5, fig.height=5}
# Faceted plot of PCA cosine similarity
listN(pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) %>% 
  lapply(., function(x){
    make_distance_key(data = x, metric = "cosine") %>% 
    calculate_distance(distance_key = ., criteria_key = df_criteria)
  }) %>% 
  mapply(function(x,y) {mutate(x, model=y)}, ., names(.), SIMPLIFY = F) %>% 
  bind_rows() %>% 
  format_embeddings() %>% 
  plot_distance()+
  facet_wrap(~model, scales = "free_y")+
  geom_violin()+
  stat_summary(fun = mean, geom = "point") +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.3) +
  scale_y_continuous(expand = expansion(mult = c(0,0.25)))
  
```


# Centroid analysis


```{r}
# Function to calculate centroids in multi-dimensional space
calculate_centroids <- function(df){
  df %>% 
    rownames_to_column("feature") %>% 
    right_join(df_criteria) %>% 
    nest(.by = criteria) %>% 
    mutate(data = map(data, function(df){
      df %>% 
        drop_na() %>% 
        distinct() %>% 
        column_to_rownames("feature") %>% 
        apply(MARGIN = 2, FUN = mean)
    })) %>% 
    unnest_wider(data) %>% 
    column_to_rownames("criteria")
}

# Function to switch between distances in a single line
custom_dist <- function(df, method = "euclidean"){
  if (method == "euclidean"){
    return(as.matrix(dist(df)))
  }
  if (method == "cosine"){
    return(lsa::cosine(t(as.matrix(df))))
  }
}
```


### Centroid distance heatmap
```{r, fig.width=4.5, fig.height=4, message = F}
heatmap_wrapper <- function(data, method){
  name <- as.character(substitute(data))
  calculate_centroids(data) %>% 
    custom_dist(method = method) %>% 
    pheatmap::pheatmap(color = viridis::viridis(100, direction = -1), main = name)
}
```

```{r, fig.width=4.5, fig.height=4, message = F}
# Euclidean distance between criteria centroids based on full embeddings
heatmap_wrapper(data = df_embeddings_chatgpt, method = "euclidean")
heatmap_wrapper(data = df_embeddings_voyage, method = "euclidean")
heatmap_wrapper(data = df_embeddings_gemini, method = "euclidean")
heatmap_wrapper(data = df_embeddings_mistral, method = "euclidean")
```
```{r, fig.width=4.5, fig.height=4, message = F}
# Cosine distance between criteria centroids based on full embeddings
heatmap_wrapper(data = df_embeddings_chatgpt, method = "cosine")
heatmap_wrapper(data = df_embeddings_voyage, method = "cosine")
heatmap_wrapper(data = df_embeddings_gemini, method = "cosine")
heatmap_wrapper(data = df_embeddings_mistral, method = "cosine")
```

### Multi model centroid distance

```{r}
dist_wrapper <- function(data){
  as.data.frame(data$x) %>% 
  calculate_centroids() %>% 
  custom_dist(method = "cosine") %>% 
  as.data.frame() %>% 
  rownames_to_column("V1") %>% 
  pivot_longer(-V1, names_to = "V2", values_to = "metric")
}

dist_wrapper(pca_chatgpt)
```
```{r, fig.width=3.5, fig.height=4}
centroid_similarity_plot <- function(...){
  # Compile data
  df <- listN(...) %>% 
    lapply(., dist_wrapper) %>%  
    mapply(function(x,y) {mutate(x, model=y)}, ., names(.), SIMPLIFY = F) %>% 
    bind_rows()
  
  # Format data
  df <- df %>% 
    unite(comp, V1, V2) %>% 
    filter(comp %in% c("MCAS - Consortium_MCAS - Alternative", "SLE - EULAR-ACR_SLE - SLICC")) %>% 
    mutate(comp = gsub("_", "\nvs. ", comp)) %>%  
    format_embeddings() 
  
  # Plot data
  df %>% 
    ggplot(aes(x = comp, y = metric, color = model))+
    geom_point(position = position_dodge(width = 0.75))+
    theme_bw() +
    ggpubr::stat_compare_means(aes(group = comp), method = "wilcox.test", label = "p", vjust = 1, show.legend = F, size = 3)+
    theme(axis.text.x = element_text(angle =90, hjust =1)) +
    labs(x=NULL, y="Cosine similarity") +
    ylim(-0.1,1) +
    scale_color_brewer(palette = "Set1") +
    labs(color = "")
}


centroid_similarity_plot(pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) 
```



```{r}
unique(df_criteria$criteria  )
```

### Multi model centroid heatmap

```{r, fig.width=5.5, fig.height=3.5}
# custom_heatmap2 <- function(data, 
#                            title, 
#                            metric, 
#                            color_scale = hcl.colors(3, "Earth"), 
#                            midpoint = NULL, 
#                            symmetric = T, 
#                            font_size=10,
#                            dendrogram_weight = unit(10, "mm"),
#                            legend_params = list(NULL)){
#   scale_max <- ifelse(symmetric,max(abs(data)),max(data))
#   scale_min <- ifelse(symmetric,-max(abs(data)),min(data))
#   scale_mid <- scale_min + (scale_max - scale_min)/2
#   
#   midpoint <- ifelse(is.null(midpoint), scale_mid, midpoint)
#   
#   color_function <-circlize::colorRamp2(c(scale_min,midpoint,scale_max), color_scale)
#   
# 
#   annotation_data <- data.frame(
#   rownames = rownames(data),
#   model = str_extract(rownames(data), "gpt|voyage|gemini|mistral"),
#   criteria = str_extract(rownames(data), "Migraine - ICHD3|Kawasaki - AHA|SLE - EULAR-ACR|SLE - SLICC|MCAS - Consortium|MCAS - Alternative")
# ) %>% 
#   column_to_rownames("rownames")
# 
#   model_colors <- colorspace::lighten(brewer.pal(4, "Dark2"), amount = -0.1)
#   names(model_colors) <- unique(annotation_data$model)
#   
#   criteria_colors <- colorspace::lighten(brewer.pal(6, "Set1"), amount = 0.3)
#   names(criteria_colors) <- unique(annotation_data$criteria)
#   
#   col_annotation <- HeatmapAnnotation(
#     Model = annotation_data$model,
#     Criteria = annotation_data$criteria,
#     col = list(Model = model_colors, Criteria = criteria_colors)
#   )
#   
#   ComplexHeatmap::Heatmap(
#     data,
#     col = color_function,
#     top_annotation = col_annotation,
#     show_row_names = FALSE,
#     show_column_names = FALSE,
#     cluster_columns = TRUE,
#     cluster_rows = TRUE,
#     
#     column_title = title,
#     name = metric,
#     column_dend_height  = dendrogram_weight,
#     row_dend_width = dendrogram_weight,
#   )
#   
# }
#   
# custom_heatmap2(cosine_data, 
#                 color_scale = RColorBrewer::brewer.pal(5, "BrBG")[c(1,3,5)], 
#                 title = " ", 
#                 metric = "Cosine\nsimilarity", 
#                 symmetric = T,
#                 font_size = 8)  
#   

```
### Average centroid heatmap
```{r}
# plt_3 <- as.data.frame(pca_embedding$x) %>% 
#   calculate_centroids() %>% 
#   custom_dist(method = "euclidean") %>% 
#   # pheatmap::pheatmap(color = viridis::viridis(100, direction = -1))
#   ComplexHeatmap::Heatmap(
#     col = viridis::viridis(100, direction = -1), 
#     name= "Euclidean distance",
#     heatmap_legend_param = list(direction = "horizontal"),
#     rect_gp = grid::gpar(col = "black", lwd = 1),
#     row_names_gp = grid::gpar(fontsize = label_size),  # Adjust font size for row labels
#     column_names_gp = grid::gpar(fontsize = label_size)  # Adjust font size for column labels
#   )

```


```{r}
centroid_heatmap <- function(label_size=6, title_size=9){
listN(pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) %>% 
  lapply(., dist_wrapper) %>%  
  mapply(function(x,y) {mutate(x, model=y)}, ., names(.), SIMPLIFY = F) %>% 
  bind_rows() %>% 
  unite(comp, V1, V2) %>% 
  summarise(metric = mean(metric), .by = "comp") %>% 
  separate(comp, into = c("V1", "V2"), sep = "_") %>% 
  pivot_wider(names_from = "V2", values_from = "metric") %>% 
  column_to_rownames("V1") %>% 
  ComplexHeatmap::Heatmap(
    col = viridis::viridis(100), 
    name= "Cosine similarity",
    heatmap_legend_param = list(
      direction = "horizontal", 
      title_gp  = grid::gpar(fontsize = title_size),
      labels_gp = gpar(fontsize = label_size)
      ),
    rect_gp = grid::gpar(col = "black", lwd = 1),
    row_names_gp = grid::gpar(fontsize = label_size),  # Adjust font size for row labels
    column_names_gp = grid::gpar(fontsize = label_size),
    # row_names_gp = grid::gpar(fontsize = cp_font),  # Adjust font size for row labels
  # column_names_gp = grid::gpar(fontsize = cp_font)
  )
}

centroid_heatmap()
```

### Centroid distance heatmap

### Dendrogram significance
```{r, fig.width=6, fig.height=6, message = F}
# cosine <- function(x) {
#   x <- as.matrix(x)
#   y <- t(x) %*% x
#   res <- 1 - y / (sqrt(diag(y)) %*% t(sqrt(diag(y))))
#   res <- as.dist(res)
#   attr(res, "method") <- "cosine"
#   return(res)
# }
# 
# 
# pvclust_pca <- as.data.frame(pca_embedding$x) %>% 
#   calculate_centroids() %>% 
#   t() %>% 
#   pvclust::pvclust(nboot = 500, method.dist = cosine, quiet = T)
# plot(pvclust_pca)
# pvclust::pvrect(pvclust_pca, alpha = 0.95)
```


# UMAP 
```{r, message = F}
# # names(umap::umap.defaults)
# set.seed(1234)
# umap_gpt <- umap::umap(df_embeddings)
# # umap_cluster <- umap::umap(df_embeddings, n_components = 2)
```

### UMAP plot

```{r, message = F}
# # Plot UMAP of embeddings
# umap_gpt$layout %>% 
#   as.data.frame() %>% 
#   rownames_to_column("feature") %>% 
#   left_join(df_criteria) %>% 
#   drop_na() %>% 
#   ggplot(aes(x=V1, y=V2, color = criteria))+
#   geom_point(size = 1) +
#   theme_bw() +
#   scale_color_brewer(palette = "Dark2")+
#   scale_fill_brewer(palette = "Dark2")
```

# Final figure
```{r, fig.width=6, fig.height=6, message=F}
# plt_1 <- pca_embedding$x[,c(x,y)] %>% 
#   as.data.frame() %>% 
#   rownames_to_column("feature") %>% 
#   left_join(df_criteria) %>% 
#   drop_na() %>% 
#   ggplot(aes(x=!!sym(x), y=!!sym(y), color = criteria))+
#   geom_point(size = 0.5) +
#   geom_point(data = . %>% group_by(criteria) %>% summarise_at(vars(contains("PC")), mean), size = 3, shape = 21, color = "black", aes(fill = criteria))+
#   # stat_ellipse(size = 2, type = "t", level = 0.95)+
#   # facet_wrap(~criteria) +
#   theme_bw()+
#   scale_color_brewer(palette = "Dark2")+
#   scale_fill_brewer(palette = "Dark2") +
#   labs(fill = "", color = "")
# 
# plt_2 <- df_compare_euc %>% 
#   ggplot(aes(x = criteria_pair, y = distance))+
#   stat_summary(fun = mean, geom = "point", size = 1) +
#   stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.5)+
#   ggpubr::stat_pvalue_manual(
#     ggpubr::compare_means(distance ~ criteria_pair, df_compare_euc, method = "wilcox.test"),
#     label = "p = {p.adj}",
#     y.position = 55.6,
#     tip.length = 0.001
#   )+
#   theme_bw() +
#   theme(axis.text.x = element_text(angle =90, hjust =1)) +
#   labs(x="", y="Euclidean distance") +
#   coord_cartesian(ylim=c(NA,55.75))
# 
# cp_font <- 9
# plt_3 <- as.data.frame(pca_embedding$x) %>% 
#   calculate_centroids() %>% 
#   custom_dist(method = "euclidean") %>% 
#   # pheatmap::pheatmap(color = viridis::viridis(100, direction = -1))
#   ComplexHeatmap::Heatmap(
#     col = viridis::viridis(100, direction = -1), 
#     name= "Euclidean\ndistance",
#     rect_gp = grid::gpar(col = "black", lwd = 1),
#     row_names_gp = grid::gpar(fontsize = cp_font),  # Adjust font size for row labels
#   column_names_gp = grid::gpar(fontsize = cp_font)  # Adjust font size for column labels
#   )
# 
# # cowplot::plot_grid(
# # cowplot::plot_grid(plt_1, plt_2, nrow = 1, rel_widths = c(0.7,0.3), align = "h", axis = "tb"),
# # cowplot::plot_grid(NULL, plt_3$gtable, NULL, nrow =1, rel_widths = c(0.2, 0.6,0.15)),
# # ncol = 1)
# 
# plt_fig <- cowplot::plot_grid(
#   cowplot::plot_grid(
#     NULL,
#     plt_1,
#     NULL,
#     nrow = 1,
#     rel_widths = c(0.1, 0.8, 0.1),
#     align = "h",
#     axis = "tb",
#     labels = c("", "A", "")
#   ),
#   # cowplot::plot_grid(plt_2, NULL, plt_3$gtable, nrow =1, rel_widths = c(0.3, 0.1, 0.7), align = "h", axis = "tb", labels = c("B","C")),
#   cowplot::plot_grid(
#     plt_2,
#     NULL,
#     cowplot::plot_grid(
#       grid::grid.grabExpr(ComplexHeatmap::draw(plt_3)),
#       NULL,
#       ncol = 1,
#       rel_heights = c(0.9, 0.1)
#     ),
#     nrow = 1,
#     rel_widths = c(0.3, 0.051, 0.7),
#     labels = c("B", "", "C")
#   ),
#   ncol = 1,
#   rel_heights = c(0.4, 0.6)
# )
# 
# plt_fig
```
```{r}
# ggsave(here("figures/2_Criteria_embedding.pdf"), plot=plt_fig, height = 6, width = 6)
```

# Altenative layout
```{r, fig.width=7, fig.height=3.5, message=F}
# title_size <- 9
# label_size <- 6
# 
# apply_text_formatting <- list(theme(
#   axis.text = element_text(size = label_size),
#   axis.title = element_text(size = title_size),
#   legend.text = element_text(size = label_size),
#   legend.key.height = unit(0.4, 'cm')
#   ))
# 
# plt_1 <- pca_embedding$x[,c(x,y)] %>% 
#   as.data.frame() %>% 
#   rownames_to_column("feature") %>% 
#   left_join(df_criteria) %>% 
#   drop_na() %>% 
#   ggplot(aes(x=!!sym(x), y=!!sym(y), color = criteria))+
#   geom_point(size = 0.5) +
#   geom_point(data = . %>% group_by(criteria) %>% summarise_at(vars(contains("PC")), mean), size = 3, shape = 21, color = "black", aes(fill = criteria))+
#   theme_bw()+
#   scale_color_brewer(palette = "Dark2")+
#   scale_fill_brewer(palette = "Dark2") +
#   labs(fill = "", color = "") +
#   theme(legend.position = "bottom") +
#   guides(color = guide_legend(ncol = 2))
# 
# plt_2 <- df_compare_euc %>% 
#   ggplot(aes(x = criteria_pair, y = distance))+
#   stat_summary(fun = mean, geom = "point", size = 1) +
#   stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.5)+
#   ggpubr::stat_pvalue_manual(
#     ggpubr::compare_means(distance ~ criteria_pair, df_compare_euc, method = "wilcox.test"),
#     label = "p = {p.adj}",
#     y.position = 55.6,
#     tip.length = 0.001, label.size = 3
#   )+
#   theme_bw() +
#   theme(axis.text.x = element_text(angle =90, hjust =1)) +
#   labs(x="", y="Euclidean distance") +
#   coord_cartesian(ylim=c(NA,55.75))
# 
# plt_3 <- as.data.frame(pca_embedding$x) %>% 
#   calculate_centroids() %>% 
#   custom_dist(method = "euclidean") %>% 
#   # pheatmap::pheatmap(color = viridis::viridis(100, direction = -1))
#   ComplexHeatmap::Heatmap(
#     col = viridis::viridis(100, direction = -1), 
#     name= "Euclidean distance",
#     heatmap_legend_param = list(direction = "horizontal"),
#     rect_gp = grid::gpar(col = "black", lwd = 1),
#     row_names_gp = grid::gpar(fontsize = label_size),  # Adjust font size for row labels
#     column_names_gp = grid::gpar(fontsize = label_size)  # Adjust font size for column labels
#   )
# 
# plt_fig <- cowplot::plot_grid(
#     plt_1 + apply_text_formatting,
#     plt_2 + apply_text_formatting,
#     grid::grid.grabExpr(ComplexHeatmap::draw(plt_3, heatmap_legend_side = 'bottom')),
#     rel_widths = c(0.9, 0.5, 1),
#     axis = 'bt',
#     align = 'h',
#     labels = LETTERS[1:3],
#     nrow = 1
# )
# 
# plt_fig
```

```{r}
# ggsave(here("figures/2_Criteria_embedding.pdf"), plot=plt_fig, height = 3.5, width = 7)
```

# Re layout
```{r, fig.height=3.5, fig.width=7.5}
title_size <- 9
label_size <- 6
legend_x_pad <- 4
legend_y_pad <- 2

apply_text_formatting <- list(theme(
  axis.text = element_text(size = label_size),
  axis.title = element_text(size = title_size),
  legend.text = element_text(size = label_size),
  strip.text = element_text(size = label_size+1),
  legend.key.height = unit(0.4, 'cm'),
  legend.box.background = element_rect(color = "black", size = 1),
  legend.margin = margin(t = legend_y_pad, r = legend_x_pad, b = legend_y_pad, l = legend_x_pad*1.1),
  legend.spacing.x = unit(-0.15, 'cm'),                           # Horizontal spacing between legend items
  legend.spacing.y = unit(0, 'cm'),
  # legend.box.spacing = unit(0, "cm")
  ))


plt_widths <- c(1.1, 0.01, 0.5, 0.01, 0.9)

plt_row <- cowplot::plot_grid(
  multi_pca_centroid_plot(criteria_key = df_criteria, components = c(1,3), pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) +theme(legend.position = "bottom", legend.direction = "horizontal")+apply_text_formatting,
  NULL,
  centroid_similarity_plot(pca_chatgpt, pca_voyage, pca_gemini, pca_mistral) +theme(legend.position = "bottom", legend.direction = "horizontal")+ guides(color = guide_legend(ncol = 1))+apply_text_formatting ,
  NULL,
  grid::grid.grabExpr(ComplexHeatmap::draw(centroid_heatmap(label_size = label_size, title_size = title_size), heatmap_legend_side = 'bottom')),
  nrow = 1,
  rel_widths = plt_widths
)

label_row <- cowplot::plot_grid(
  NULL, NULL, NULL, NULL, NULL,
  nrow = 1,
  rel_widths = plt_widths,
  labels = c("A","","B","","C")
)

plt_fig <- plot_grid(
  label_row,
  plt_row,
  ncol = 1,
  rel_heights = c(0.075,1)
)

plt_fig
```
```{r}
ggsave(here("figures/2_Criteria_embedding.pdf"), plot=plt_fig, height = 3.5, width = 7.5)
```


